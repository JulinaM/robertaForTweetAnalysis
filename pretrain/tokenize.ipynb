{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Ic6GPnGQiO9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Sep 28 12:14:33 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8     9W / 250W |    104MiB / 12188MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro P6000        Off  | 00000000:81:00.0 Off |                  Off |\n",
      "| 26%   21C    P8     8W / 250W |  15264MiB / 24449MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2783      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    0   N/A  N/A      2914      G   /usr/bin/gnome-shell               59MiB |\n",
      "|    1   N/A  N/A      7449      C   /usr/bin/python3                 2587MiB |\n",
      "|    1   N/A  N/A     21289      C   .../envs/crawler/bin/python3    12673MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvidia-smi --query-gpu=name --format=csv,noheader | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sulqhTj6hqvM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ArJE6fM5iK43"
   },
   "outputs": [],
   "source": [
    "#Set the path to the data folder, datafile and output folder and files\n",
    "\n",
    "op_folder_name = 'oct2022'\n",
    "\n",
    "root_folder = '/users/kent/jmaharja/drugAbuse/'\n",
    "output_folder = os.path.abspath(os.path.join(root_folder, 'output/'+ op_folder_name))\n",
    "model_folder = os.path.abspath(os.path.join(output_folder, 'RoBERTaMLM/'))\n",
    "tokenizer_folder = os.path.abspath(os.path.join(output_folder, 'TokRoBERTa/'))\n",
    "\n",
    "datafile= '2020_01_01.csv'\n",
    "testfile= '20161007.csv'\n",
    "outputfile = 'submission.csv'\n",
    "\n",
    "input_folder = os.path.abspath(os.path.join(root_folder, 'input/'))\n",
    "datafile_path = os.path.abspath(os.path.join(input_folder, datafile))\n",
    "testfile_path = os.path.abspath(os.path.join(input_folder, testfile))\n",
    "outputfile_path = os.path.abspath(os.path.join(output_folder, outputfile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115630, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df =pd.read_csv(datafile_path,lineterminator='\\n',skipinitialspace=True, usecols= ['text'])\n",
    "train_df.rename(columns={'text':'Tweet'}, inplace=True)\n",
    "train_df = train_df.dropna()\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2281116, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 =pd.read_csv('/users/kent/jmaharja/drugAbuse/input/2020_01_31_CleanedTweets.csv',\n",
    "                lineterminator='\\n',\n",
    "                skipinitialspace=True\n",
    "                )\n",
    "df2.drop(df2.columns[[0, 1]], axis=1, inplace=True)\n",
    "df2.rename({'text': 'Tweet'}, axis=1, inplace=True)\n",
    "df = pd.concat([train_df,df2])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHg-_qMajz9q"
   },
   "source": [
    "# Build a Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dkfwjxpsjMwi"
   },
   "outputs": [],
   "source": [
    "# Drop the files from the output dir\n",
    "!mkdir -p {output_folder}\n",
    "txt_files_dir = output_folder + \"/text_split\"\n",
    "\n",
    "!rm -rf {txt_files_dir}\n",
    "!mkdir {txt_files_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xtXxaWocj9QK"
   },
   "outputs": [],
   "source": [
    "# Store values in a dataframe column (Series object) to files, one file per record\n",
    "# The prefix is a unique ID to avoid to overwrite a text file\n",
    "def column_to_files(column, prefix, txt_files_dir):\n",
    "    i=prefix\n",
    "    for row in column.to_list():\n",
    "      file_name = os.path.join(txt_files_dir, str(i)+'.txt')\n",
    "      try:\n",
    "        f = open(file_name, 'wb')\n",
    "        f.write(row.encode('utf-8'))\n",
    "        f.close()\n",
    "      except Exception as e: \n",
    "        print(row, e) \n",
    "      i+=1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1MUD7ZjkAf_"
   },
   "outputs": [],
   "source": [
    "data = df[\"Tweet\"]\n",
    "data = data.replace(\"\\n\",\" \")\n",
    "prefix = 0\n",
    "#Create a file for every description value\n",
    "prefix = column_to_files(data, prefix, txt_files_dir)\n",
    "print(prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5gW-Fd6mkaBE"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gGXzTW_QkdG9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 21min 19s, sys: 2h 50min 48s, total: 9h 12min 8s\n",
      "Wall time: 1h 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "paths = [str(x) for x in Path('/users/kent/jmaharja/drugAbuse/output/oct2022/').glob(\"text_split/*.txt\")]\n",
    "\n",
    "# Initialize a tokenizer\n",
    "tokenizer = ByteLevelBPETokenizer(lowercase=True)\n",
    "\n",
    "# Customize training\n",
    "tokenizer.train(files=paths, vocab_size=8192, min_frequency=2,\n",
    "                show_progress=True,\n",
    "                special_tokens=[\n",
    "                                \"<s>\",\n",
    "                                \"<pad>\",\n",
    "                                \"</s>\",\n",
    "                                \"<unk>\",\n",
    "                                \"<mask>\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "sArosNLXki_k"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/users/kent/jmaharja/drugAbuse/output/oct2022/TokRoBERTa/vocab.json',\n",
       " '/users/kent/jmaharja/drugAbuse/output/oct2022/TokRoBERTa/merges.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the Tokenizer to disk\n",
    "tokenizer.save_model(tokenizer_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/users/kent/jmaharja/drugAbuse/output/oct2022/TokRoBERTa'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eJMY1o_Hko46"
   },
   "outputs": [],
   "source": [
    "# Prepare the tokenizer\n",
    "tokenizer._tokenizer.post_processor = BertProcessing(\n",
    "    (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    ")\n",
    "tokenizer.enable_truncation(max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "a85eD5-7oOQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=6, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"cook some blue.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"cook some blue.\").special_tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'cook', 'Ġsome', 'Ġblue', '.', '</s>']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"cook some blue.\").tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Drug-Abuse-Tweets-onRobert",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
