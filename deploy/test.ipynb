{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_folder = '/users/kent/jmaharja/drugAbuse/output/oct2022/TokRoBERTa'\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetModel(RobertaPreTrainedModel):\n",
    "    def __init__(self, conf, n_classes):\n",
    "        super(TweetModel, self).__init__(conf)\n",
    "        self.roberta = transformers.RobertaModel.from_pretrained('/users/kent/jmaharja/drugAbuse/output/oct2022/RoBERTaMLM/', config=conf)\n",
    "        self.drop_out = nn.Dropout(0.5)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.classifier = nn.Linear(768, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.roberta(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.drop_out(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /users/kent/jmaharja/drugAbuse/output/oct2022/RoBERTaMLM/ were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /users/kent/jmaharja/drugAbuse/output/oct2022/RoBERTaMLM/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=8192,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    "    hidden_size=768,\n",
    "    pad_token_id=1\n",
    ")\n",
    "\n",
    "model = TweetModel(config, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load('/users/kent/jmaharja/drugAbuse/finetune/checkpoint/best_ftc_model_state2023_02_20-03_15PM.bin'))\n",
    "# model = torch.load('/users/kent/jmaharja/drugAbuse/finetune/checkpoint/best_ftc_model_state2023_02_20-03_15PM.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"Some shots from my shoot for F.I.T. Studio. Coach Fred\"\n",
    "encoded_tweet = tokenizer.encode_plus(\n",
    "    tweet,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    pad_to_max_length=True,\n",
    "    add_special_tokens=True,\n",
    "    padding='max_length',\n",
    "    return_token_type_ids=True,\n",
    "    return_tensors='pt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoded_tweet['input_ids'].to(device)\n",
    "attention_mask = encoded_tweet['attention_mask'].to(device)\n",
    "token_type_ids = encoded_tweet['token_type_ids'].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet text: Some shots from my shoot for F.I.T. Studio. Coach Fred\n",
      "Substance type  : tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "output = model(input_ids, attention_mask, token_type_ids)\n",
    "_, prediction = torch.max(output, dim=1)\n",
    "print(f'Tweet text: {tweet}')\n",
    "print(f'Substance type  : {prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%curl` not found.\n"
     ]
    }
   ],
   "source": [
    "%curl -X POST -H \"Content-Type: application/json\" -d '{\"tweet\":\"Some shots from my shoot for F.I.T. Studio. Coach Fred\"}' http://localhost:5000/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Serialize tensor to JSON string\n",
    "tensor_json = json.dumps(prediction.tolist())\n",
    "\n",
    "# Print JSON string\n",
    "print(tensor_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some shots from my shoot for F.I.T. Studio. Coach Fred--->[0]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet + \"--->\" + tensor_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
