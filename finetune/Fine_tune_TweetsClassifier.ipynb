{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://colab.research.google.com/github/DhavalTaunk08/NLP_scripts/blob/master/sentiment_analysis_using_roberta.ipynb#scrollTo=HMqQTafXEaei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjlMoTtP6zh4",
    "outputId": "044618cf-e1c2-4bca-f68d-1c188f9af205",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 18 10:52:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8     9W / 250W |    103MiB / 12188MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro P6000        Off  | 00000000:81:00.0 Off |                  Off |\n",
      "| 26%   21C    P8     7W / 250W |      2MiB / 24449MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2783      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    0   N/A  N/A      2914      G   /usr/bin/gnome-shell               60MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l59zl8RALeLS",
    "outputId": "6398f014-8da0-4246-a1c6-273ed1ead195"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOf9SIPJlkb4",
    "outputId": "4e017760-6961-4b6a-9091-4ea0012a1fc4"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
    "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\n",
    "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 8\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@aaronaxline @friskycarolina was livid to watc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anyways. im starting my diet on Sunday. i was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alcohol and drugs is good for the mind but not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now that's jus sad ðŸ˜‚ #BuckeyeNation\"62% of Ohi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bro do you ever get in those moods where you j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>How much coke she did no wonder age OD'd. Damn.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4463</th>\n",
       "      <td>Ain't no salary cap in the dope game ain't no ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4464</th>\n",
       "      <td>Aw man they busting out the nose candy &amp;amp; f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4465</th>\n",
       "      <td>They say crack kill nigga my crack sell #21Savage</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4466</th>\n",
       "      <td>crackhead on my street tried to sell me a kid'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4467 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  label\n",
       "0     @aaronaxline @friskycarolina was livid to watc...      1\n",
       "1     anyways. im starting my diet on Sunday. i was ...      1\n",
       "2     Alcohol and drugs is good for the mind but not...      1\n",
       "3     Now that's jus sad ðŸ˜‚ #BuckeyeNation\"62% of Ohi...      1\n",
       "4     Bro do you ever get in those moods where you j...      1\n",
       "...                                                 ...    ...\n",
       "4462    How much coke she did no wonder age OD'd. Damn.      1\n",
       "4463  Ain't no salary cap in the dope game ain't no ...      1\n",
       "4464  Aw man they busting out the nose candy &amp; f...      1\n",
       "4465  They say crack kill nigga my crack sell #21Savage      1\n",
       "4466  crackhead on my street tried to sell me a kid'...      1\n",
       "\n",
       "[4467 rows x 2 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 =pd.read_csv('/users/kent/jmaharja/drugAbuse/input/Tweets_Spring_Summer_2021_coded.csv',\n",
    "                lineterminator='\\n',\n",
    "                skipinitialspace=True,\n",
    "                )\n",
    "df1['label']= 1\n",
    "df1.drop(df1.columns[[0, 2,3,4]], axis=1, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =pd.read_csv('/users/kent/jmaharja/drugAbuse/input/2020_01_31_CleanedTweets.csv',\n",
    "                lineterminator='\\n',\n",
    "                skipinitialspace=True\n",
    "                )\n",
    "df2.drop(df2.columns[[0, 1]], axis=1, inplace=True)\n",
    "df2.rename({'text': 'Tweet'}, axis=1, inplace=True)\n",
    "\n",
    "df2['label']= 0\n",
    "df2= df2[:5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@aaronaxline @friskycarolina was livid to watc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>anyways. im starting my diet on Sunday. i was ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alcohol and drugs is good for the mind but not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Now that's jus sad ðŸ˜‚ #BuckeyeNation\"62% of Ohi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bro do you ever get in those moods where you j...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>USER one tiny slice institutional racism fashi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>USER least one arrest far grand central manhat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>USER make nice cup tea brew liberal tear delic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>rick santorum waste time call witness get trut...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>USER USER fly bed millisecond</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9467 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  label\n",
       "0     @aaronaxline @friskycarolina was livid to watc...      1\n",
       "1     anyways. im starting my diet on Sunday. i was ...      1\n",
       "2     Alcohol and drugs is good for the mind but not...      1\n",
       "3     Now that's jus sad ðŸ˜‚ #BuckeyeNation\"62% of Ohi...      1\n",
       "4     Bro do you ever get in those moods where you j...      1\n",
       "...                                                 ...    ...\n",
       "4995  USER one tiny slice institutional racism fashi...      0\n",
       "4996  USER least one arrest far grand central manhat...      0\n",
       "4997  USER make nice cup tea brew liberal tear delic...      0\n",
       "4998  rick santorum waste time call witness get trut...      0\n",
       "4999                      USER USER fly bed millisecond      0\n",
       "\n",
       "[9467 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2[:5000]\n",
    "df = pd.concat([df1,df2])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i29J68U9Sk9S"
   },
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choosing sequence length\n",
    "token_lens = []\n",
    "for txt in df.Tweet:\n",
    "  tokens = tokenizer.encode(txt)\n",
    "  token_lens.append(len(tokens))\n",
    "sns.distplot(token_lens)\n",
    "plt.xlim([0, 200])\n",
    "plt.xlabel('Token count')\n",
    "\n",
    "# MAX_LEN = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "iMU0a8QCTR3L"
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "from transformers import RobertaTokenizerFast\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "# Create the tokenizer from a trained one\n",
    "tokenizer_folder = '/users/kent/jmaharja/drugAbuse/output/sept2022/TokRoBERTa'\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_folder, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "eu0sHr3QhB0l"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class Tweet_DataSet(Dataset):\n",
    "   def __init__(self, data, tokenizer, max_len):\n",
    "    self.data = data\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "  \n",
    "   def __len__(self):\n",
    "    return len(self.data)\n",
    "  \n",
    "   def __getitem__(self, index:int):\n",
    "    data_row = self.data.iloc[index]\n",
    "    tweet = data_row.Tweet\n",
    "    labels = data_row['label']\n",
    "    encoding = tokenizer.encode_plus(tweet,\n",
    "                                     None,\n",
    "                                     max_length = MAX_LEN,\n",
    "                                     truncation=True,\n",
    "                                     pad_to_max_length=True,\n",
    "                                     add_special_tokens=True,\n",
    "                                     padding=MAX_LEN,\n",
    "                                     return_token_type_ids=True)\n",
    "\n",
    "    return {\n",
    "      'tweet_text': tweet,\n",
    "      'input_ids': torch.tensor(encoding.input_ids, dtype=torch.long),\n",
    "      'attention_mask':  torch.tensor(encoding.attention_mask, dtype=torch.long),\n",
    "      'token_type_ids': torch.tensor(encoding.token_type_ids, dtype=torch.long),\n",
    "      'targets': torch.tensor(labels, dtype=torch.long)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "wp8kq4BikWLs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8520, 2), (473, 2), (474, 2))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "UZy66nwyDuXp"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = Tweet_DataSet(df,tokenizer=tokenizer,max_len=max_len)\n",
    "  return DataLoader(ds, batch_size=batch_size,num_workers=4)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "# from transformers import RobertaModel, RobertaConfig, logging\n",
    "\n",
    "class TweetModel(RobertaPreTrainedModel):\n",
    "    def __init__(self, conf, n_classes):\n",
    "        super(TweetModel, self).__init__(conf)\n",
    "        self.roberta = transformers.RobertaModel.from_pretrained('/users/kent/jmaharja/drugAbuse/output/sept2022/RoBERTaMLM/', config=conf)\n",
    "        self.drop_out = nn.Dropout(0.3)\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.classifier = nn.Linear(768, n_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.roberta(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.drop_out(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /users/kent/jmaharja/drugAbuse/output/sept2022/RoBERTaMLM/ were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /users/kent/jmaharja/drugAbuse/output/sept2022/RoBERTaMLM/ and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import RobertaConfig\n",
    "\n",
    "config = RobertaConfig(\n",
    "    vocab_size=8192,\n",
    "    max_position_embeddings=514,\n",
    "    num_attention_heads=12,\n",
    "    num_hidden_layers=6,\n",
    "    type_vocab_size=1,\n",
    "    hidden_size=768,\n",
    "    pad_token_id=1\n",
    ")\n",
    "\n",
    "model = TweetModel(config, 2)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "WigPq2Cz3Aqa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "#training\n",
    "EPOCHS = 16\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "  optimizer,\n",
    "  num_warmup_steps=0,\n",
    "  num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "-lMBp21F3G3Q"
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "  model = model.train()\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "     \n",
    "  for d in data_loader:\n",
    "    input_ids = d[\"input_ids\"].to(device)\n",
    "    attention_mask = d[\"attention_mask\"].to(device)\n",
    "    token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "    targets = d[\"targets\"].to(device)\n",
    "\n",
    "    outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "\n",
    "    big_val, big_idx = torch.max(outputs, dim=1)\n",
    "    correct_predictions += torch.sum(big_idx == targets)\n",
    "\n",
    "    loss = loss_fn(outputs, targets)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    loss.backward()\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "  return correct_predictions.double()/n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "_DEVC-rR3Rb6"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "  model = model.eval()\n",
    "\n",
    "  losses = []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids=token_type_ids\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      correct_predictions += torch.sum(preds == targets)\n",
    "\n",
    "      loss = loss_fn(outputs, targets)\n",
    "      losses.append(loss.item())\n",
    "\n",
    "  return correct_predictions.double()/n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnG-gI1f3XUC",
    "outputId": "a39a6bce-c0e5-4490-ea63-517efb30fa94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.03715697081572718 accuracy 0.9893192488262911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 6.084695044895246e-05 accuracy 1.0\n",
      "\n",
      "Epoch 2/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.0035927296548168937 accuracy 0.9985915492957746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 5.1419122792140114e-05 accuracy 1.0\n",
      "\n",
      "Epoch 3/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.0006902068962969848 accuracy 0.9998826291079812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 0.00024271800290686467 accuracy 1.0\n",
      "\n",
      "Epoch 4/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 5.3993941153793255e-05 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 2.9053898060737993e-06 accuracy 1.0\n",
      "\n",
      "Epoch 5/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.0010031101722205716 accuracy 0.9998826291079812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 2.5030198078942097e-06 accuracy 1.0\n",
      "\n",
      "Epoch 6/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 3.9275159117342055e-06 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 1.8065097719954792e-06 accuracy 1.0\n",
      "\n",
      "Epoch 7/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 2.9481553889386467e-06 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 1.3973653191593864e-06 accuracy 1.0\n",
      "\n",
      "Epoch 8/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 2.4279333830811328e-06 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 1.1152929156802807e-06 accuracy 1.0\n",
      "\n",
      "Epoch 9/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.8941573581316237e-06 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 9.295811423726264e-07 accuracy 1.0\n",
      "\n",
      "Epoch 10/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.5539673191677303e-06 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 7.6522770958339e-07 accuracy 1.0\n",
      "\n",
      "Epoch 11/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.4632231653930494e-06 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 5.802063971790024e-07 accuracy 1.0\n",
      "\n",
      "Epoch 12/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.1124835271012086e-06 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 5.21567736200268e-07 accuracy 1.0\n",
      "\n",
      "Epoch 13/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 9.879203406957012e-07 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 4.6996565477760063e-07 accuracy 1.0\n",
      "\n",
      "Epoch 14/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 1.1499067541330433e-05 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 6.657361609541113e-07 accuracy 1.0\n",
      "\n",
      "Epoch 15/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 8.107981610050129e-07 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 6.341969329544857e-07 accuracy 1.0\n",
      "\n",
      "Epoch 16/16\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 8.229102341572466e-07 accuracy 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val   loss 6.025195555518319e-07 accuracy 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "# %%time\n",
    "\n",
    "# set to True if you want to train the model\n",
    "# otherwise use the existing trained model\n",
    "FORCE_TRAIN = True\n",
    "\n",
    "# download trained model\n",
    "# !gdown --id 1QQ2d0_yFStL2rXz2eHoXpgRMvPWtMMeX\n",
    "\n",
    "\n",
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "\n",
    "#   modelPath = \"/content/best_model_state.bin\"\n",
    "#   if (exists(modelPath) and FORCE_TRAIN == False ): # if model exists load it otherwise rebuild\n",
    "#     torch.load(modelPath)\n",
    "#     break # exit out of training\n",
    "  \n",
    "\n",
    "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "  print('-' * 10)\n",
    "\n",
    "  train_acc, train_loss = train_epoch(\n",
    "    model,\n",
    "    train_data_loader,    \n",
    "    loss_fn, \n",
    "    optimizer, \n",
    "    device, \n",
    "    scheduler, \n",
    "    len(df_train)\n",
    "  )\n",
    "\n",
    "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "  val_acc, val_loss = eval_model(\n",
    "    model,\n",
    "    val_data_loader,\n",
    "    loss_fn, \n",
    "    device, \n",
    "    len(df_val)\n",
    "  )\n",
    "\n",
    "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "  print()\n",
    "\n",
    "  history['train_acc'].append(train_acc)\n",
    "  history['train_loss'].append(train_loss)\n",
    "  history['val_acc'].append(val_acc)\n",
    "  history['val_loss'].append(val_loss)\n",
    "\n",
    "  if val_acc > best_accuracy:\n",
    "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "    best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "SGWOG9FxDwhr",
    "outputId": "caccda71-7a38-4b86-f8a5-bf3f8fe2b68e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 506,
       "width": 732
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMgX1q0vDx4C",
    "outputId": "fff07436-f581-40c9-87e8-9306aa66608b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9957805907172995"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, _ = eval_model(\n",
    "  model,\n",
    "  test_data_loader,\n",
    "  loss_fn,\n",
    "  device,\n",
    "  len(df_test)\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "l5-QMqvSDx8h"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "  model = model.eval()\n",
    "  \n",
    "  review_texts = []\n",
    "  predictions = []\n",
    "  prediction_probs = []\n",
    "  real_values = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for d in data_loader:\n",
    "\n",
    "      texts = d[\"tweet_text\"]\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "      targets = d[\"targets\"].to(device)\n",
    "\n",
    "      outputs = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "      review_texts.extend(texts)\n",
    "      predictions.extend(preds)\n",
    "      prediction_probs.extend(probs)\n",
    "      real_values.extend(targets)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "  return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xr7hsCroDyBJ",
    "outputId": "c0f726e5-930f-404e-b637-e6d8d194f851"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n",
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
    "  model,\n",
    "  test_data_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_review_texts,y_pred_probs, y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.numpy>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = y_test.numpy\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/kent/jmaharja/.local/lib/python3.6/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>readme</th>\n",
       "      <th>Real</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Pred-prob</th>\n",
       "      <th>All Pred-probs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER day go think video HTTPURL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.501921e-07</td>\n",
       "      <td>[0.99999976, 2.5019213e-07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>get joshua quiz seventeen member attract you H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.726962e-07</td>\n",
       "      <td>[0.99999964, 3.7269623e-07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>play tradjik lawless algeric break app google ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.090407e-07</td>\n",
       "      <td>[0.99999964, 4.0904072e-07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shiiiiit this @vincestaples song is so dope. N...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>[2.9127887e-07, 0.99999976]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER USER USER USER get it remember â€œ black ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.664348e-07</td>\n",
       "      <td>[0.99999976, 2.6643482e-07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>USER know measles reset immune system even per...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.572248e-07</td>\n",
       "      <td>[0.99999976, 2.5722483e-07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>Good luck to the freshman and JV teams as they...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999998e-01</td>\n",
       "      <td>[2.9732195e-07, 0.99999976]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>But you guys were drunk https://t.co/d8hdjxHqPu</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>[3.042073e-07, 0.99999964]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Basketball https://t.co/InJA5FHuOj</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.999996e-01</td>\n",
       "      <td>[3.0058405e-07, 0.99999964]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>USER rabbitfacedumpling HTTPURL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.533804e-07</td>\n",
       "      <td>[0.99999976, 2.5338045e-07]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>474 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                readme  Real  Predicted  \\\n",
       "0                      USER day go think video HTTPURL     0          0   \n",
       "1    get joshua quiz seventeen member attract you H...     0          0   \n",
       "2    play tradjik lawless algeric break app google ...     0          0   \n",
       "3    Shiiiiit this @vincestaples song is so dope. N...     1          1   \n",
       "4    USER USER USER USER get it remember â€œ black ha...     0          0   \n",
       "..                                                 ...   ...        ...   \n",
       "469  USER know measles reset immune system even per...     0          0   \n",
       "470  Good luck to the freshman and JV teams as they...     1          1   \n",
       "471    But you guys were drunk https://t.co/d8hdjxHqPu     1          1   \n",
       "472                 Basketball https://t.co/InJA5FHuOj     1          1   \n",
       "473                    USER rabbitfacedumpling HTTPURL     0          0   \n",
       "\n",
       "        Pred-prob               All Pred-probs  \n",
       "0    2.501921e-07  [0.99999976, 2.5019213e-07]  \n",
       "1    3.726962e-07  [0.99999964, 3.7269623e-07]  \n",
       "2    4.090407e-07  [0.99999964, 4.0904072e-07]  \n",
       "3    9.999998e-01  [2.9127887e-07, 0.99999976]  \n",
       "4    2.664348e-07  [0.99999976, 2.6643482e-07]  \n",
       "..            ...                          ...  \n",
       "469  2.572248e-07  [0.99999976, 2.5722483e-07]  \n",
       "470  9.999998e-01  [2.9732195e-07, 0.99999976]  \n",
       "471  9.999996e-01   [3.042073e-07, 0.99999964]  \n",
       "472  9.999996e-01  [3.0058405e-07, 0.99999964]  \n",
       "473  2.533804e-07  [0.99999976, 2.5338045e-07]  \n",
       "\n",
       "[474 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred_probs_pd = [y.numpy() for y in y_pred_probs]\n",
    "someListOfLists = list(zip(y_review_texts, y_test.numpy(), y_pred.numpy(), y_pred_probs[:, 1:].numpy().squeeze(), y_pred_probs_pd ))\n",
    "npa = np.asarray(someListOfLists)\n",
    "dff = pd.DataFrame(someListOfLists, columns = ['readme', 'Real', 'Predicted', 'Pred-prob', 'All Pred-probs' ])\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wgq_aUGOG4dK",
    "outputId": "e5a6c79a-b6e6-4626-bb6d-09257257a846"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           Y       1.00      1.00      1.00       262\n",
      "           N       1.00      1.00      1.00       212\n",
      "\n",
      "    accuracy                           1.00       474\n",
      "   macro avg       1.00      1.00      1.00       474\n",
      "weighted avg       1.00      1.00      1.00       474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['Y', 'N']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "2QtoYqSlHTG2",
    "outputId": "829b4ac4-d49e-4694-e52a-8de90666b2e2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 492,
       "width": 677
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_confusion_matrix(confusion_matrix):\n",
    "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
    "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
    "  plt.ylabel('True sentiment')\n",
    "  plt.xlabel('Predicted sentiment');\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm, index=['Y', 'N'], columns=['Y', 'N'])\n",
    "show_confusion_matrix(df_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TweetsClassification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "055e6760af2a4cc99a5ab6c89d09a631": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "06f7bff32930487389f4bcd11a046ba9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07d860f569894b60a8a57586b5ed22e5",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_55de3f028970426a9904fc9123459878",
      "value": 435797
     }
    },
    "07d860f569894b60a8a57586b5ed22e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "085cdd69c17e4436af7f950636b90c6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0cbbf3d4487644b89158c60e70dbb607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_133db211b5044e0e8b39b129adf709e3",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_865c669b97224cc2be141212d5de0af5",
      "value": 29
     }
    },
    "121058277c9a4920a7f9c87da8d9cf18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "133db211b5044e0e8b39b129adf709e3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18263e27139341a884f597dc6e3e175f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "203bbb759bfc42fb8895a162e08d3226": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d4f2c2b28864980b41c8720823fef6e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_121058277c9a4920a7f9c87da8d9cf18",
      "value": " 570/570 [00:00&lt;00:00, 14.6kB/s]"
     }
    },
    "228b86f13326402ab8378ff0c8fbbff1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2674f4b837014c9083f38a737dd757aa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "283139806e8a4a9a9246bc7f6c5b3898": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5195c3fff00b4392a9858558f5367ac6",
       "IPY_MODEL_99e1bdc66761476e8ac577a44b9d6d5a",
       "IPY_MODEL_936e7ea6788547eb961fab7f0ac3fc9c"
      ],
      "layout": "IPY_MODEL_d850d2931d484a9c809dbc3ca011257d"
     }
    },
    "2a76d71ad3fa40cbaf398b49e0adefb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f10ffa3df1f44dd919c0baee3d30ac3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "315ee8c0093846a091788364c7688c13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31a79d60573546178856a921e0f5c190": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_315ee8c0093846a091788364c7688c13",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2a76d71ad3fa40cbaf398b49e0adefb9",
      "value": " 426k/426k [00:00&lt;00:00, 368kB/s]"
     }
    },
    "340192f505574f72b7496f865608ffe3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c8fcb504c8349f793e935ec4164ca1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d4f2c2b28864980b41c8720823fef6e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46eb3c39e9bf4951b9fb668f310be103": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48e43c1295b2416c8a46e50c57057f40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bcd18d241cc14d6e8f912d07bdb2b351",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_6ef2499da99743f5bfd432942be8236c",
      "value": "Downloading: 100%"
     }
    },
    "5195c3fff00b4392a9858558f5367ac6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_340192f505574f72b7496f865608ffe3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_98620c0254194f9cad64e2d4ffafcf72",
      "value": "Downloading: 100%"
     }
    },
    "530cb8fbb3f54dd4a4c37f3160802f43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55de3f028970426a9904fc9123459878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5c84a1017fc14329b2b09c69b719d1ab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64f780fa37514b4fa75910a78554cb68": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6755a7bfcf034309a02ab1fca75ede77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69f9f6a970f14a8897cdd5c02b74cf4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee0878d1399e45b68ca43c9c9cd81d9a",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e53b976695aa41af944e3f2f8596d1b0",
      "value": " 208k/208k [00:00&lt;00:00, 327kB/s]"
     }
    },
    "6ef2499da99743f5bfd432942be8236c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f8284261f834b719a0fd599bb03c8b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e84104b0dafc43ebb14817cd20708d56",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_085cdd69c17e4436af7f950636b90c6e",
      "value": "Downloading: 100%"
     }
    },
    "73faa65f3d7f4dd5b726cf98298602e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d515148f8814097acdf61376e700410": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "865c669b97224cc2be141212d5de0af5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8a4c66093db14c25b8aa2b9d15760dd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b4ac1dcba5749169a74d7c704c458ae",
       "IPY_MODEL_0cbbf3d4487644b89158c60e70dbb607",
       "IPY_MODEL_aeac7285f899476884e5ec6dc9a8c521"
      ],
      "layout": "IPY_MODEL_5c84a1017fc14329b2b09c69b719d1ab"
     }
    },
    "8b4ac1dcba5749169a74d7c704c458ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64f780fa37514b4fa75910a78554cb68",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_efa4acc3b227476a99a79a0d1d6c024f",
      "value": "Downloading: 100%"
     }
    },
    "936e7ea6788547eb961fab7f0ac3fc9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_73faa65f3d7f4dd5b726cf98298602e7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_228b86f13326402ab8378ff0c8fbbff1",
      "value": " 416M/416M [00:14&lt;00:00, 30.3MB/s]"
     }
    },
    "95204170f8f74eec91ae42ef1b9b3c15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "98620c0254194f9cad64e2d4ffafcf72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99e1bdc66761476e8ac577a44b9d6d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6755a7bfcf034309a02ab1fca75ede77",
      "max": 435779157,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_18263e27139341a884f597dc6e3e175f",
      "value": 435779157
     }
    },
    "a413ea9ae9954bfd828f9baa0b704ccd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aeac7285f899476884e5ec6dc9a8c521": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bacd9a4d7c624d5eaea8fdcc59c03ebe",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a413ea9ae9954bfd828f9baa0b704ccd",
      "value": " 29.0/29.0 [00:00&lt;00:00, 726B/s]"
     }
    },
    "bacd9a4d7c624d5eaea8fdcc59c03ebe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bcd18d241cc14d6e8f912d07bdb2b351": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b211e0c60443f3889149135db6bfeb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_055e6760af2a4cc99a5ab6c89d09a631",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_46eb3c39e9bf4951b9fb668f310be103",
      "value": 570
     }
    },
    "ca8c2d4b884b4ac794576be0c009f68e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f8284261f834b719a0fd599bb03c8b2",
       "IPY_MODEL_dc921144d4f44c499eb91e1c8ab92bdb",
       "IPY_MODEL_69f9f6a970f14a8897cdd5c02b74cf4a"
      ],
      "layout": "IPY_MODEL_7d515148f8814097acdf61376e700410"
     }
    },
    "cc0aaf21f85b4cf1942fdb0e1f62b902": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d850d2931d484a9c809dbc3ca011257d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc921144d4f44c499eb91e1c8ab92bdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f10ffa3df1f44dd919c0baee3d30ac3",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95204170f8f74eec91ae42ef1b9b3c15",
      "value": 213450
     }
    },
    "e53b976695aa41af944e3f2f8596d1b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e635e63ca713478a961c98edc3e1ca7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_48e43c1295b2416c8a46e50c57057f40",
       "IPY_MODEL_06f7bff32930487389f4bcd11a046ba9",
       "IPY_MODEL_31a79d60573546178856a921e0f5c190"
      ],
      "layout": "IPY_MODEL_cc0aaf21f85b4cf1942fdb0e1f62b902"
     }
    },
    "e84104b0dafc43ebb14817cd20708d56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee0878d1399e45b68ca43c9c9cd81d9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efa4acc3b227476a99a79a0d1d6c024f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f442c127804f41abad386e33e09c05db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2674f4b837014c9083f38a737dd757aa",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_3c8fcb504c8349f793e935ec4164ca1a",
      "value": "Downloading: 100%"
     }
    },
    "fbc0fbf3c4784098b65f3c9a6d954fca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f442c127804f41abad386e33e09c05db",
       "IPY_MODEL_c4b211e0c60443f3889149135db6bfeb",
       "IPY_MODEL_203bbb759bfc42fb8895a162e08d3226"
      ],
      "layout": "IPY_MODEL_530cb8fbb3f54dd4a4c37f3160802f43"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
